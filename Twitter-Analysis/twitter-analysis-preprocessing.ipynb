{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8327d6",
   "metadata": {},
   "source": [
    "### It is recommended to have new virtual environment configured. Checkout [this](https://towardsdatascience.com/how-to-create-a-virtual-environment-and-use-it-on-jupyter-notebook-6c0b7b1cfca0) if you are not sure how to do it in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages to be installed\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install nltk\n",
    "# !pip install emoji;\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install pandoc\n",
    "# !pip install -U jupyter_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1c4e4",
   "metadata": {},
   "source": [
    "## Understanding the data -\n",
    "Understand the data by doing following basic checks on dataframe.\n",
    "- Get the shape of data\n",
    "- Get the number of columns and their datatype of data\n",
    "- Check how much data is null and if its okay to delete the rows\n",
    "- Run the basic statistics on overall dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data & making copy to experiment\n",
    "raw_df = pd.read_csv('data/twitter-jan-mar.csv')\n",
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the basic understanding of data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ade8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking columns, null values & their datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9179dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic statistics - below method only provides stats of numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c73b0",
   "metadata": {},
   "source": [
    "## Basic Preprocessing Steps-\n",
    "\n",
    "From the overview of the data above, we can decide the basic cleaning steps.\n",
    "- We can delete the id column as it will not add any insight to the analysis\n",
    "- Considering the significant rows in total, we can delete null rows\n",
    "- Datatype of date column is object, we can change it to datetime to serve the analysis better\n",
    "- Columns such as 'like_count' & 'retweet_count' can't be float, we can convert them into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete id column\n",
    "df.drop(columns=\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all null values from rows\n",
    "df = df.dropna(axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column to datetime datatype\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to integer\n",
    "df[\"like_count\"] = df[\"like_count\"].astype(\"int32\")\n",
    "df[\"retweet_count\"] = df[\"retweet_count\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e718258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate changes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ab7ef",
   "metadata": {},
   "source": [
    "## Analysing textual data\n",
    "\n",
    "Now we only have the 'content' column as textual data which we need to analyse, preprocess & process in detail  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d17f9",
   "metadata": {},
   "source": [
    "### Understanding textual data\n",
    "- It seems they are all tweets by users\n",
    "- Load of times users only mentioned 'chat gpt' phrase only as a tweet\n",
    "- Tweets contain loads of unclean data which can add noise to the data such as\n",
    "    - punctuations\n",
    "    - links\n",
    "    - stopwords\n",
    "    - html tags\n",
    "    - emoji\n",
    "    - uneven cases (capital & small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aef4e6",
   "metadata": {},
   "source": [
    "# Preprocessing text data\n",
    "\n",
    "### Standard preprocessing of text data includes -\n",
    " - Consistent Cases- Make all text to lowercase\n",
    " - URLs & Tags - Remove all web urls & HTML Tags\n",
    " - Stopwords - Remove all stopwords to access context in better way\n",
    " - Punctuations - Get rid of punctuation symbols in text\n",
    " - Emoji - Emoji can play a part in recognising the tone of text so convert them into texts\n",
    " - Tokenize - Convert text into consistent tokens\n",
    " - Lemmatize - Extract root words from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to preprocess the text\n",
    "\n",
    "def convert_lower(text):\n",
    "    \"\"\"This function converts the input text into lowercase\"\"\"\n",
    "    \n",
    "    modified_text = str(text).lower()\n",
    "#     print(\"Converting to lower\")\n",
    "    return modified_text\n",
    "\n",
    "def remove_url(text):\n",
    "    \"\"\"This function finds the pattern of url in input text and removes it.\"\"\"\n",
    "    \n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    modified_text = url_pattern.sub(r'', text)\n",
    "#     print(\"Removing URLs..\")\n",
    "    return modified_text\n",
    "\n",
    "def remove_tags(text):\n",
    "    \"\"\"This function finds the pattern of HTML tags in input text and removes it.\"\"\"\n",
    "    \n",
    "    tags_pattern = re.compile('<.*?>')\n",
    "    modified_text = tags_pattern.sub(r'', text)\n",
    "#     print(\"Removing HTML tags..\")\n",
    "    return modified_text\n",
    "\n",
    "def remove_punctuation_without_hashtags_and_mentions(text):\n",
    "    \"\"\"This function extracts punctuation from input text except hashtags & mentions\"\"\"\n",
    "    punctuation = string.punctuation + string.digits\n",
    "    # remove hashtags & mentions from punctuation list as we will need them\n",
    "    filtered_punc = punctuation.replace(\"@\",\"\").replace(\"#\",\"\")\n",
    "    if isinstance(text, str):\n",
    "        modified_text = ''.join(char for char in text if char not in filtered_punc)\n",
    "#     print(\"Removing punctuations..\")\n",
    "    return modified_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"This function removes the defined stopwords from input text\"\"\"\n",
    "    # download stopwords from whole nltk corpora\n",
    "    nltk.download('stopwords')\n",
    "    # remove duplicates\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    words = text.split()\n",
    "    modified_words = [word for word in words if word.lower() not in stop_words]\n",
    "    modified_text = \" \".join(modified_words)\n",
    "#     print(\"Removing stopwords..\")\n",
    "    return modified_text\n",
    "\n",
    "def demojize(text):\n",
    "    \"\"\"This function de-emojize emoticons for contextual analysis\"\"\"\n",
    "    modified_text = emoji.demojize(text)\n",
    "    return modified_text\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"This function tokenize input text\"\"\"\n",
    "    modified_text = nlp(text)\n",
    "#     print(\"Tokenizing text..\")\n",
    "    return modified_text\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    \"\"\"This function lemmatize the input text\"\"\"\n",
    "    doc = nlp(text)\n",
    "    modified_text = \" \".join([token.lemma_ if token.lemma_ != '-PRON-' else token.text for token in doc])\n",
    "#     print(\"Tokenizing text..\")\n",
    "    return modified_text\n",
    "\n",
    "def extract_mentions(df):\n",
    "    \"\"\"This function extract all mention accounts and stores into different column\"\"\"\n",
    "    df[\"accounts_mentioned\"] = df[\"content\"].apply(lambda x: re.findall(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9_]+)\", x))\n",
    "    return df\n",
    "\n",
    "def extract_hashtags(df):\n",
    "    \"\"\"This function extract hashtags from column and creates different column\"\"\"\n",
    "    df[\"hashtags\"] = df[\"content\"].apply(lambda x: re.findall(\"#(\\w+)\",x))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45334693",
   "metadata": {},
   "source": [
    "### Extract accounts mentioned & hashtags in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_mentions(df)\n",
    "df = extract_hashtags(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c001d1",
   "metadata": {},
   "source": [
    "### PreProcess Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"] = df[\"content\"].apply(convert_lower)\n",
    "df[\"content\"] = df[\"content\"].apply(remove_url)\n",
    "df[\"content\"] = df[\"content\"].apply(remove_tags)\n",
    "df[\"content\"] = df[\"content\"].apply(remove_punctuation_without_hashtags_and_mentions)\n",
    "df[\"content\"] = df[\"content\"].apply(remove_stopwords)\n",
    "df[\"content\"] = df[\"content\"].apply(demojize)\n",
    "df[\"content\"] = df[\"content\"].apply(tokenize)\n",
    "df[\"content\"] = df[\"content\"].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6657b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content\"] = df[\"content\"].str.replace(\":\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd59cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01ff3c",
   "metadata": {},
   "source": [
    "### Export the cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned-twitter-data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_analysis",
   "language": "python",
   "name": "twitter_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
